{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjOr6TPkRpkdU6yh3v7Wys",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayur2829/GenAI_Document_Summarization_Integration/blob/main/Copy_of_Niveus_GenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdPECyNMlJOj"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install langchain chromadb pypdf openpyxl pandas unstructured -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Select up to 50 files manually"
      ],
      "metadata": {
        "id": "sqZ1Wxy8lXCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ans extract data from Excel and PDF\n",
        "\n",
        "!pip install PyPDF2 -q"
      ],
      "metadata": {
        "id": "nkgQN7YX5uk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "A3rOJa1D6sto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract pdf file text\n",
        "\n",
        "def extract_pdf_text(file_path):\n",
        "    text = ''\n",
        "    with open(file_path, 'rb') as f:\n",
        "        reader = PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() or ''\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "b7ApTJZ476hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Excel file text\n",
        "\n",
        "!pip install openpyxl xlrd -q\n",
        "\n",
        "def extract_excel_text(file_path):\n",
        "    ext = file_path.split('.')[-1].lower()\n",
        "    engine = 'openpyxl' if ext == 'xlsx' else 'xlrd'\n",
        "    text = ''\n",
        "    df = pd.read_excel(file_path, engine=engine)\n",
        "    text = df.astype(str).apply(lambda x: ' '.join(x), axis=1).str.cat(sep=' ')\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "drQ8g8yh8BJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of documents with content and metadata\n",
        "\n",
        "documents = []\n",
        "\n",
        "for file in uploaded.keys():\n",
        "    ext = file.split('.')[-1].lower()\n",
        "    try:\n",
        "        if ext == 'pdf':\n",
        "            content = extract_pdf_text(file)\n",
        "        elif ext in ['xls', 'xlsx']:\n",
        "            content = extract_excel_text(file)\n",
        "        else:\n",
        "            continue\n",
        "        documents.append({'filename': file, 'text': content})\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file}: {e}\")"
      ],
      "metadata": {
        "id": "4ivlrLjo8Gu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "id": "_jpNWZke8PaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding in ChromeDB\n",
        "\n",
        "!pip install -U langchain-community\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.docstore.document import Document\n",
        "import uuid\n"
      ],
      "metadata": {
        "id": "hpHfyMOv8Xmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using HuggingFace embeddings\n",
        "\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "huggingfacehub_api_key = getpass(\"Enter your Hugging Face API token: \")\n",
        "# Set the API token as an environment variable\n",
        "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = huggingfacehub_api_key\n",
        "\n",
        "embedding_function = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")"
      ],
      "metadata": {
        "id": "tJMGmi9U95tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_function"
      ],
      "metadata": {
        "id": "Y4WHW6iE-Ufo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ChromaDB\n",
        "db = Chroma(embedding_function=embedding_function, persist_directory=\"./chroma_db\")"
      ],
      "metadata": {
        "id": "FptWi7uYB3I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db"
      ],
      "metadata": {
        "id": "okOny-oZB66g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert documents to LangChain format\n",
        "docs = [Document(page_content=d[\"text\"], metadata={\"source\": d[\"filename\"]}) for d in documents]\n",
        "db.add_documents(docs)"
      ],
      "metadata": {
        "id": "KGcSc-97B8JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db"
      ],
      "metadata": {
        "id": "ZZXazw-OB_rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query Documents Simmilarity search\n",
        "# seacrh from pdf\n",
        "\n",
        "query = \"Genai is it future\"\n",
        "results = db.similarity_search(query, k=3)\n",
        "\n",
        "for i, r in enumerate(results):\n",
        "    print(f\"Result {i+1} - {r.metadata['source']}\\n{r.page_content[:500]}\\n{'-'*50}\\n\")"
      ],
      "metadata": {
        "id": "hMqB2-N8CF7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search from excel\n",
        "\n",
        "query = \"nls exper every year\"\n",
        "results = db.similarity_search(query, k=3)\n",
        "\n",
        "for i, r in enumerate(results):\n",
        "    print(f\"Result {i+1} - {r.metadata['source']}\\n{r.page_content[:500]}\\n{'-'*50}\\n\")"
      ],
      "metadata": {
        "id": "zkzyO9oVCevr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check filename\n",
        "all_filenames = [d.metadata[\"source\"] for d in docs]\n",
        "print(\"Available documents:\", all_filenames[::-5])"
      ],
      "metadata": {
        "id": "UWhD03KbC_Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Update a Document's Embedding\n",
        "\n",
        "def update_document(db, filename, new_text):\n",
        "    try:\n",
        "        db.delete([filename])\n",
        "        doc = Document(page_content=new_text, metadata={\"source\": filename})\n",
        "        db.add_documents([doc])\n",
        "        print(f\"Updated: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Update failed for {filename}: {e}\")"
      ],
      "metadata": {
        "id": "0G9nTmk5E5DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"This is the UPDATED version of report1.pdf with revised financials.\"\n",
        "update_document(db, 'SpecialIssueCFP (1).pdf', new_text)"
      ],
      "metadata": {
        "id": "IpK8_X9BDkQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete a Document\n",
        "\n",
        "def delete_document(db, filename):\n",
        "    try:\n",
        "        db.delete([filename])\n",
        "        print(f\"Deleted: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Delete failed for {filename}: {e}\")"
      ],
      "metadata": {
        "id": "a4J2yVxhDpVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_document(db, 'rice.xls')"
      ],
      "metadata": {
        "id": "H1E5QRLYDx-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace embedding one document to other\n",
        "\n",
        "def replace_document(db, target_filename, source_text):\n",
        "    try:\n",
        "        db.delete([target_filename])\n",
        "        doc = Document(page_content=source_text, metadata={\"source\": target_filename})\n",
        "        db.add_documents([doc])\n",
        "        print(f\"Replaced content in: {target_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Replace failed for {target_filename}: {e}\")"
      ],
      "metadata": {
        "id": "F6DF2xI3GKUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_text = \"Content originally from another report, now replacing summary.pdf\"\n",
        "replace_document(db, 'Make Your LLM Fully Utilize the Context (1).pdf', source_text)"
      ],
      "metadata": {
        "id": "a8vYQhmvGK7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain Summarization of a document\n",
        "\n",
        "!pip install transformers langchain huggingface_hub\n",
        "\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "from langchain.chains.summarize import load_summarize_chain"
      ],
      "metadata": {
        "id": "wJCsrGdXJU4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", tokenizer=\"sshleifer/distilbart-cnn-12-6\")\n",
        "llm = HuggingFacePipeline(pipeline=summarizer)"
      ],
      "metadata": {
        "id": "ogTI97JrMFjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load summarization chain\n",
        "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n"
      ],
      "metadata": {
        "id": "72Chezd-NL-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_filenames = [d.metadata[\"source\"] for d in docs]\n",
        "print(\"Available documents:\", all_filenames[:])"
      ],
      "metadata": {
        "id": "j8b33oBAOXM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a document from vector store\n",
        "print(docs[0])\n",
        "doc_to_summarize = docs[-1]  #summarizing last document 'SpecialIssueCFP (1).pdf'\n"
      ],
      "metadata": {
        "id": "dDUQmKdWNZr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the document content is a string\n",
        "doc_content = doc_to_summarize.page_content\n",
        "if not isinstance(doc_content, str):\n",
        "    doc_content = str(doc_content)\n",
        "\n",
        "# Truncate the document to a maximum length if needed\n",
        "max_length = 512 # Example maximum length\n",
        "if len(doc_content) > max_length:\n",
        "    doc_content = doc_content[:max_length]"
      ],
      "metadata": {
        "id": "TZcWq8vcNamM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the document content with the truncated string\n",
        "doc_to_summarize = Document(page_content=doc_content, metadata=doc_to_summarize.metadata)\n",
        "\n",
        "# Run summarization\n",
        "summary = chain.run([doc_to_summarize])\n",
        "print(\"Summary:\\n\", summary)"
      ],
      "metadata": {
        "id": "_JITSrinNjdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zlyEU7ScN3wd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}